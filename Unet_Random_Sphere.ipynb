{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dko1217/porousmedia/blob/main/Unet_Random_Sphere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bixMOLQ45WNr"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YExzJx1Sy3-Q"
      },
      "source": [
        "## System Information"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "1UhP42s_PYoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9NE57KoDT-n"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27EFtvthy6Yp"
      },
      "source": [
        "## Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_VHOIejB4OMr"
      },
      "outputs": [],
      "source": [
        "!pip install hdf5storage\n",
        "from hdf5storage import loadmat\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "from numpy.random import default_rng\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "import scipy\n",
        "from scipy import io\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.random.set_seed(280675)\n",
        "np.random.seed(280675)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My\\ Drive/DarcyUnet Unit Cell/\n",
        "\n",
        "print('tensorflow version : {}'.format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doLp4_6qWh7d"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CJOnWnUIEB7"
      },
      "outputs": [],
      "source": [
        "def minmax_transform(x, x_min=0, x_range=1):\n",
        "  x = ( x - x_min ) / x_range\n",
        "  return x\n",
        "\n",
        "\n",
        "def shift_augmentation(my_solid, my_vel, shift_range, vel_dir):\n",
        "\n",
        "  my_aug_solid = np.ones_like(my_solid)\n",
        "  my_aug_vel = np.ones_like(my_vel)\n",
        "\n",
        "  shift_x = shift_range[0]\n",
        "  shift_y = shift_range[1]\n",
        "\n",
        "  if(shift_x < 0):\n",
        "    my_aug_solid[:shift_x,:,:] = my_solid[-1*shift_x:,:,:]\n",
        "    my_aug_solid[shift_x:,:,:] = np.flip(my_solid, axis=0 )[:-1*shift_x,:,:]\n",
        "\n",
        "    my_aug_vel[:shift_x,:,:] = my_vel[-1*shift_x:,:,:]\n",
        "    if(vel_dir[0] == 'x'):\n",
        "      my_aug_vel[shift_x:,:,:] = np.flip(-1*my_vel, axis=0 )[:-1*shift_x,:,:]\n",
        "    elif(vel_dir[0] == 'y'):\n",
        "      my_aug_vel[shift_x:,:,:] = np.flip(my_vel, axis=0 )[:-1*shift_x,:,:]\n",
        "    else:\n",
        "      my_aug_vel[shift_x:,:,:] = np.flip(my_vel, axis=0 )[:-1*shift_x,:,:]\n",
        "\n",
        "  elif(shift_x > 0):\n",
        "    my_aug_solid[:shift_x,:,:] = np.flip(my_solid, axis=0 )[-1*shift_x:,:,:]\n",
        "    my_aug_solid[shift_x:,:,:] = my_solid[:-1*shift_x,:,:]\n",
        "\n",
        "    if(vel_dir[0] == 'x'):\n",
        "      my_aug_vel[:shift_x,:,:] = np.flip(-1*my_vel, axis=0 )[-1*shift_x:,:,:]\n",
        "    elif(vel_dir[0] == 'y'):\n",
        "      my_aug_vel[:shift_x,:,:] = np.flip(my_vel, axis=0 )[-1*shift_x:,:,:]\n",
        "    else:\n",
        "      my_aug_vel[:shift_x,:,:] = np.flip(my_vel, axis=0 )[-1*shift_x:,:,:]\n",
        "    my_aug_vel[shift_x:,:,:] = my_vel[:-1*shift_x,:,:]\n",
        "  else:\n",
        "    my_aug_solid = my_solid\n",
        "    my_aug_vel = my_vel\n",
        "\n",
        "  my_solid = my_aug_solid\n",
        "  my_vel = my_aug_vel\n",
        "\n",
        "  my_aug_solid = np.ones_like(my_solid)\n",
        "  my_aug_vel = np.ones_like(my_vel)\n",
        "\n",
        "  if(shift_y < 0):\n",
        "    my_aug_solid[:,:shift_y,:] = my_solid[:,-1*shift_y:,:]\n",
        "    my_aug_solid[:,shift_y:,:] = np.flip(my_solid, axis=1 )[:,:-1*shift_y,:]\n",
        "\n",
        "    my_aug_vel[:,:shift_y,:] = my_vel[:,-1*shift_y:,:]\n",
        "    if(vel_dir[0] == 'x'):\n",
        "      my_aug_vel[:,shift_y:,:] = np.flip(my_vel, axis=1 )[:,:-1*shift_y,:]\n",
        "    elif(vel_dir[0] == 'y'):\n",
        "      my_aug_vel[:,shift_y:,:] = np.flip(-1*my_vel, axis=1 )[:,:-1*shift_y,:]\n",
        "    else:\n",
        "      my_aug_vel[:,shift_y:,:] = np.flip(my_vel, axis=1 )[:,:-1*shift_y,:]\n",
        "      \n",
        "  elif(shift_y > 0):\n",
        "    my_aug_solid[:,:shift_y,:] = np.flip(my_solid, axis=1 )[:,-1*shift_y:,:]\n",
        "    my_aug_solid[:,shift_y:,:] = my_solid[:,:-1*shift_y,:]\n",
        "\n",
        "    if(vel_dir[0] == 'x'):\n",
        "      my_aug_vel[:,:shift_y,:] = np.flip(my_vel, axis=1 )[:,-1*shift_y:,:]\n",
        "    elif(vel_dir[0] == 'y'):\n",
        "      my_aug_vel[:,:shift_y,:] = np.flip(-1*my_vel, axis=1 )[:,-1*shift_y:,:]\n",
        "    else:\n",
        "      my_aug_vel[:,:shift_y,:] = np.flip(my_vel, axis=1 )[:,-1*shift_y:,:]\n",
        "    my_aug_vel[:,shift_y:,:] = my_vel[:,:-1*shift_y,:]\n",
        "  else:\n",
        "    my_aug_solid = my_solid\n",
        "    my_aug_vel = my_vel\n",
        "\n",
        "  return my_aug_solid, my_aug_vel\n",
        "\n",
        "\n",
        "def flip_augmentation(my_solid, my_vel, vel_dir, axis):\n",
        "\n",
        "  my_aug_solid = np.flip(my_solid, axis=axis)\n",
        "\n",
        "  if(vel_dir[0] == 'x'):\n",
        "    if(axis == 0):\n",
        "      my_aug_vel = np.flip(-1*my_vel, axis=axis)\n",
        "    else:\n",
        "      my_aug_vel = np.flip(my_vel, axis=axis)\n",
        "  elif(vel_dir[0] == 'y'):\n",
        "    if(axis == 1):\n",
        "      my_aug_vel = np.flip(-1*my_vel, axis=axis)\n",
        "    else:\n",
        "      my_aug_vel = np.flip(my_vel, axis=axis)\n",
        "  else:\n",
        "    my_aug_vel = np.flip(my_vel, axis=axis)\n",
        "\n",
        "  return my_aug_solid, my_aug_vel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Loss"
      ],
      "metadata": {
        "id": "SJzZnnCXzU4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def div_loss1(y_true, y_pred):\n",
        "\n",
        "  scale = 1\n",
        "\n",
        "  mse = tf.math.reduce_mean( tf.math.square(y_true - y_pred) )\n",
        "  \n",
        "  dVxdx_true = (y_true[:,2:,1:-1,1:-1,0] - y_true[:,:-2,1:-1,1:-1,0])/2\n",
        "  dVydy_true = (y_true[:,1:-1,2:,1:-1,1] - y_true[:,1:-1,:-2,1:-1,1])/2\n",
        "  dVzdz_true = (y_true[:,1:-1,1:-1,2:,2] - y_true[:,1:-1,1:-1,:-2,2])/2\n",
        "  div_true = dVxdx_true + dVydy_true + dVzdz_true\n",
        "\n",
        "  dVxdx_pred = (y_pred[:,2:,1:-1,1:-1,0] - y_pred[:,:-2,1:-1,1:-1,0])/2\n",
        "  dVydy_pred = (y_pred[:,1:-1,2:,1:-1,1] - y_pred[:,1:-1,:-2,1:-1,1])/2\n",
        "  dVzdz_pred = (y_pred[:,1:-1,1:-1,2:,2] - y_pred[:,1:-1,1:-1,:-2,2])/2\n",
        "  div_pred = dVxdx_pred + dVydy_pred + dVzdz_pred\n",
        "\n",
        "  div_loss = tf.math.reduce_mean( tf.math.abs(div_true - div_pred) )\n",
        "\n",
        "  loss = mse + div_loss*scale\n",
        "  \n",
        "  return loss\n",
        "\n",
        "\n",
        "def div_loss2(y_true, y_pred):\n",
        "\n",
        "  scale = 3\n",
        "\n",
        "  mse = tf.math.reduce_mean( tf.math.square(y_true - y_pred) )\n",
        "  \n",
        "  dVxdx_pred = (y_pred[:,2:,1:-1,1:-1,0] - y_pred[:,:-2,1:-1,1:-1,0])/2\n",
        "  dVydy_pred = (y_pred[:,1:-1,2:,1:-1,1] - y_pred[:,1:-1,:-2,1:-1,1])/2\n",
        "  dVzdz_pred = (y_pred[:,1:-1,1:-1,2:,2] - y_pred[:,1:-1,1:-1,:-2,2])/2\n",
        "  div_pred = dVxdx_pred + dVydy_pred + dVzdz_pred\n",
        "\n",
        "  div_loss = tf.math.reduce_mean( tf.math.abs(div_pred) )\n",
        "\n",
        "  loss = mse + div_loss*scale\n",
        "  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "79Z81JqxzXDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv27oHYCZ-qF"
      },
      "source": [
        "# PolySphere Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGzWUeq-aDN8"
      },
      "outputs": [],
      "source": [
        "dir_data = 'Data/PolySphere'\n",
        "\n",
        "data_size = 120\n",
        "\n",
        "\"\"\"\n",
        "X : ('x')\n",
        "Y : ('y')\n",
        "Z : ('z')\n",
        "\"\"\"\n",
        "#velocity_dir = ('x')\n",
        "#velocity_dir = ('y')\n",
        "#velocity_dir = ('z')\n",
        "velocity_dir = ('x', 'y', 'z')\n",
        "\n",
        "domainRange = [1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "channel_size = len(velocity_dir)\n",
        "\n",
        "uc_solid = np.zeros( (1,data_size, data_size, data_size) )\n",
        "uc_vel = np.zeros( (1,data_size, data_size, data_size, len(velocity_dir)) )\n",
        "\n",
        "for i in range(len(domainRange)):\n",
        "  \n",
        "    uc_solid_load = loadmat( '{}/PolySphere_domain{}_deci.mat'.format(dir_data, domainRange[i]) )['solid'].astype('int')\n",
        "    uc_solid_load = uc_solid_load < 1\n",
        "    uc_solid = np.append( uc_solid, np.expand_dims(uc_solid_load, axis=0), axis=0 )\n",
        "    del uc_solid_load\n",
        "\n",
        "    uc_vel_load = np.zeros( (1, data_size, data_size, data_size, channel_size) )\n",
        "    for j in range(channel_size):\n",
        "      if(velocity_dir[j] == 'z'):\n",
        "        uc_vel_load[0,:,:,:,j] = loadmat( '{}/PolySphere_domain{}_vfield{}.mat'.format(dir_data, domainRange[i], '') )['vfield'].astype('float32')\n",
        "      else:\n",
        "        uc_vel_load[0,:,:,:,j] = loadmat( '{}/PolySphere_domain{}_vfield{}.mat'.format(dir_data, domainRange[i], velocity_dir[j]) )['vfield'].astype('float32')\n",
        "    uc_vel = np.append( uc_vel, uc_vel_load, axis=0 )\n",
        "    del uc_vel_load\n",
        "\n",
        "\n",
        "uc_solid = uc_solid[1:,:,:,:]\n",
        "uc_vel = uc_vel[1:,:,:,:,:]\n",
        "\n",
        "print('Image size : {}\\nNumber of Data : {}  {}'.format(data_size, uc_solid.shape, uc_vel.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import distance_transform_edt\n",
        "from scipy.ndimage import distance_transform\n",
        "uc_solid_edt = distance_transform_edt(uc_solid)"
      ],
      "metadata": {
        "id": "BoBmLddKO4Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnVgNqmHbAwt"
      },
      "outputs": [],
      "source": [
        "\"\"\" Normalization\n",
        "\"\"\"\n",
        "res = 20e-6\n",
        "\n",
        "x_min = 0\n",
        "x_max = 8\n",
        "\n",
        "uc_vel_norm = uc_vel/(res**2)*0.333/9270\n",
        "\n",
        "print( '\\nMean velocity : {}'.format( uc_vel_norm.mean() ) )\n",
        "print( '\\nMin velocity : {}'.format( uc_vel_norm.min() ) )\n",
        "print( '\\nMax velocity : {}'.format( uc_vel_norm.max() ) )\n",
        "\n",
        "print('\\nX_min : {} and X_max : {}'.format(x_min, x_max))\n",
        "\n",
        "uc_vel_minmax = minmax_transform(uc_vel_norm, x_min=x_min, x_range=x_max-x_min)\n",
        "\n",
        "print( '\\nMean velocity : {}'.format( uc_vel_minmax.mean() ) )\n",
        "print( '\\nMin velocity : {}'.format( uc_vel_minmax.min() ) )\n",
        "print( '\\nMax velocity : {}'.format( uc_vel_minmax.max() ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEBh1oBjHSbW"
      },
      "outputs": [],
      "source": [
        "augGen_seed = 10\n",
        "\n",
        "aug_iter = 15\n",
        "\n",
        "shift_range = 2\n",
        "flip_range = 5\n",
        "\n",
        "aug_uc_solid = np.zeros( (1, data_size, data_size, data_size) )\n",
        "aug_uc_vel = np.zeros( (1, data_size, data_size, data_size, channel_size) )\n",
        "\n",
        "\"\"\" Shift and Flip augmentation\n",
        "\"\"\"\n",
        "\n",
        "shift = data_size//shift_range\n",
        "rnd_num_gen = default_rng(augGen_seed)\n",
        "rnd_num = rnd_num_gen.integers(low=-shift, high=shift, size=(uc_solid.shape[0],aug_iter,2), endpoint=True)\n",
        "rnd_num2 = rnd_num_gen.integers(low=0, high=10, size=(uc_solid.shape[0],aug_iter,2))\n",
        "\n",
        "for i in range(uc_solid.shape[0]):\n",
        "\n",
        "  my_solid = uc_solid[i,:,:,:]\n",
        "  my_vel = uc_vel_minmax[i,:,:,:,:]\n",
        "\n",
        "  for j in range(aug_iter): \n",
        "    if(channel_size <= 1):\n",
        "\n",
        "      my_aug_solid, my_aug_vel = shift_augmentation(my_solid, my_vel[:,:,:,0], rnd_num[i,j,:], velocity_dir)\n",
        "      if(rnd_num2[i,j,0] >= flip_range):\n",
        "        my_aug_solid, my_aug_vel = flip_augmentation(my_aug_solid, my_aug_vel, velocity_dir, 0)\n",
        "      if(rnd_num2[i,j,1] >= flip_range):\n",
        "        my_aug_solid, my_aug_vel = flip_augmentation(my_aug_solid, my_aug_vel, velocity_dir, 1)\n",
        "\n",
        "      aug_uc_solid = np.append(aug_uc_solid, np.expand_dims(my_aug_solid,axis=0), axis=0)\n",
        "      aug_uc_vel = np.append(aug_uc_vel, np.expand_dims( np.expand_dims(my_aug_vel,axis=0), axis=-1 ), axis=0)\n",
        "\n",
        "    elif(channel_size == 3):\n",
        "\n",
        "      my_aug_solid, my_aug_vel_x = shift_augmentation(my_solid, my_vel[:,:,:,0], rnd_num[i,j,:], ('x'))\n",
        "      my_aug_solid, my_aug_vel_y = shift_augmentation(my_solid, my_vel[:,:,:,1], rnd_num[i,j,:], ('y'))\n",
        "      my_aug_solid, my_aug_vel_z = shift_augmentation(my_solid, my_vel[:,:,:,2], rnd_num[i,j,:], ('z'))\n",
        "\n",
        "      if(rnd_num2[i,j,0] >= flip_range):\n",
        "        my_aug_solid, my_aug_vel_x = flip_augmentation(my_aug_solid, my_aug_vel_x, ('x'), 0)\n",
        "        my_aug_solid, my_aug_vel_y = flip_augmentation(my_aug_solid, my_aug_vel_y, ('y'), 0)\n",
        "        my_aug_solid, my_aug_vel_z = flip_augmentation(my_aug_solid, my_aug_vel_z, ('z'), 0)\n",
        "      if(rnd_num2[i,j,1] >= flip_range):\n",
        "        my_aug_solid, my_aug_vel_x = flip_augmentation(my_aug_solid, my_aug_vel_x, ('x'), 1)\n",
        "        my_aug_solid, my_aug_vel_y = flip_augmentation(my_aug_solid, my_aug_vel_y, ('y'), 1)\n",
        "        my_aug_solid, my_aug_vel_z = flip_augmentation(my_aug_solid, my_aug_vel_z, ('z'), 1)\n",
        "\n",
        "      my_aug_vel = np.append( np.append(np.expand_dims(my_aug_vel_x,axis=-1), np.expand_dims(my_aug_vel_y,axis=-1), axis=-1), np.expand_dims(my_aug_vel_z,axis=-1), axis=-1 )\n",
        "\n",
        "      aug_uc_solid = np.append(aug_uc_solid, np.expand_dims(my_aug_solid,axis=0), axis=0)\n",
        "      aug_uc_vel = np.append(aug_uc_vel, np.expand_dims(my_aug_vel,axis=0), axis=0)\n",
        "\n",
        "\n",
        "aug_uc_solid = aug_uc_solid[1:,:,:,:]\n",
        "aug_uc_vel = aug_uc_vel[1:,:,:,:,:]\n",
        "\n",
        "total_number = aug_uc_solid.shape[0]\n",
        "\n",
        "val_perc = 0.1\n",
        "test_perc = 0.1\n",
        "\n",
        "train_index, val_test_index = train_test_split(np.arange(total_number), test_size = val_perc + test_perc, random_state = augGen_seed)\n",
        "val_index, test_index = train_test_split(val_test_index, test_size = test_perc/(val_perc+test_perc), random_state = augGen_seed)\n",
        "\n",
        "print( 'Number of training samples : {}\\nNumber of validation samples : {}\\nNumber of test samples : {}\\n'.format(len(train_index),len(val_index),len(test_index)) )\n",
        "\n",
        "train_data_solid = np.expand_dims(aug_uc_solid[train_index], axis=-1)\n",
        "val_data_solid = np.expand_dims(aug_uc_solid[val_index], axis=-1)\n",
        "test_data_solid = np.expand_dims(aug_uc_solid[test_index], axis=-1)\n",
        "\n",
        "train_data_vel = aug_uc_vel[train_index]\n",
        "val_data_vel = aug_uc_vel[val_index]\n",
        "test_data_vel = aug_uc_vel[test_index]\n",
        "\n",
        "print(train_data_solid.shape)\n",
        "print(val_data_solid.shape)\n",
        "print(test_data_solid.shape)\n",
        "\n",
        "print(train_data_vel.shape)\n",
        "print(val_data_vel.shape)\n",
        "print(test_data_vel.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Check"
      ],
      "metadata": {
        "id": "G_1GP63bpZI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mass loss check"
      ],
      "metadata": {
        "id": "fM6Pjiuj-zuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uc_solid_temp = uc_solid[0,:,:,:]\n",
        "uc_solid_temp = np.expand_dims(uc_solid_temp, axis=(-1))\n",
        "\n",
        "uc_vel_temp = uc_vel_minmax[0,:,:,:,:]\n",
        "\n",
        "dVxdx = (uc_vel_temp[2:,1:-1,1:-1,0] - uc_vel_temp[:-2,1:-1,1:-1,0])/2\n",
        "dVydy = (uc_vel_temp[1:-1,2:,1:-1,1] - uc_vel_temp[1:-1,:-2,1:-1,1])/2\n",
        "dVzdz = (uc_vel_temp[1:-1,1:-1,2:,2] - uc_vel_temp[1:-1,1:-1,:-2,2])/2\n",
        "div = dVxdx + dVydy + dVzdz"
      ],
      "metadata": {
        "id": "qr-3YNLw-3OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(uc_solid_temp[:,:,59,0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(uc_vel_temp[:,:,59,2])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(div[:,:,59], vmin=-0.3, vmax=0.3)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.3,0.3,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ) )"
      ],
      "metadata": {
        "id": "jydMVUquuaa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xversion = 'X1-3'\n",
        "x_model_name = 'UnetRS_Modelv{}'.format(xversion)\n",
        "x_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(x_model_name, x_model_name ) )\n",
        "\n",
        "yversion = 'Y1-1'\n",
        "y_model_name = 'UnetRS_Modelv{}'.format(yversion)\n",
        "y_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(y_model_name, y_model_name ) )\n",
        "\n",
        "zversion = 'Z1-4'\n",
        "z_model_name = 'UnetRS_Modelv{}'.format(zversion)\n",
        "z_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(z_model_name, z_model_name ) )\n",
        "\n",
        "vx_test_pred = np.float32( x_model.predict( x=[np.expand_dims(uc_solid_temp,axis=0)] ) )/2\n",
        "vy_test_pred = np.float32( y_model.predict( x=[np.expand_dims(uc_solid_temp,axis=0)] ) )/2\n",
        "vz_test_pred = np.float32( z_model.predict( x=[np.expand_dims(uc_solid_temp,axis=0)] ) )\n",
        "\n",
        "vpred_test_temp = np.append(vx_test_pred, np.append(vy_test_pred, vz_test_pred,axis=-1),axis=-1 )\n",
        "print(vpred_test_temp.shape)"
      ],
      "metadata": {
        "id": "Dnvc8Yr-GfML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_vel = np.multiply(vpred_test_temp[0,:,:,:,:],uc_solid_temp[:,:,:,:])\n",
        "#temp_vel = vpred_test_temp[0,:,:,:,:]\n",
        "\n",
        "dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "div = dVxdx + dVydy + dVzdz\n",
        "\n",
        "print(uc_solid_temp.shape)\n",
        "plt.imshow(uc_solid_temp[:,:,59,0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(temp_vel[:,:,59,2])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(div[:,:,59],vmin=-0.3,vmax=0.3)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.3,0.3,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ) )"
      ],
      "metadata": {
        "id": "7gf9gkOWKvaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_div_loss = div_loss1(np.expand_dims(uc_vel_temp,axis=0), np.expand_dims(temp_vel,axis=0))\n",
        "\n",
        "print(temp_div_loss)"
      ],
      "metadata": {
        "id": "t95g1Fc8z-da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SIsIuN2sWBS"
      },
      "source": [
        "## Augmentation test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "I-iBRfq4ND8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTU4NwKfsaTa"
      },
      "outputs": [],
      "source": [
        "temp = np.zeros( (1,20,20,1) )\n",
        "temp[0,15:,:,0] = 10\n",
        "\n",
        "plt.imshow(temp[0,:,:,0])\n",
        "plt.show()\n",
        "\n",
        "augGenTemp = ImageDataGenerator(#rotation_range=45, \n",
        "                              #width_shift_range=(data_size//4, \n",
        "                              height_shift_range=(5,5),\n",
        "                              fill_mode='reflect')\n",
        "\n",
        "iterator_temp = augGenTemp.flow(temp)\n",
        "\n",
        "\n",
        "temp2 = iterator_temp.next()\n",
        "print(temp2.shape)\n",
        "\n",
        "plt.imshow(temp2[0,:,:,0])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T3-lqqvLgTn"
      },
      "outputs": [],
      "source": [
        "temp = np.zeros( (20,20,20) )\n",
        "temp[13:,13:,:] = 10\n",
        "\n",
        "plt.imshow(temp[:,:,9])\n",
        "plt.show()\n",
        "\n",
        "rnd_num_gen = default_rng(10)\n",
        "\n",
        "# 1: height (x) \n",
        "# 2: width (y)\n",
        "#rnd_num = rnd_num_gen.integers(low=-shift_range, high=shift_range, size=2, endpoint=True)\n",
        "rnd_num = (-10,-10)\n",
        "\n",
        "my_solid = temp\n",
        "my_aug_solid = np.ones_like(temp)\n",
        "\n",
        "if(rnd_num[0] < 0):\n",
        "  my_aug_solid[:rnd_num[0],:,:] = my_solid[-1*rnd_num[0]:,:,:]\n",
        "  my_aug_solid[rnd_num[0]:,:,:] = np.flip(my_solid, axis=0 )[:-1*rnd_num[0],:,:]\n",
        "else:\n",
        "  my_aug_solid[:rnd_num[0],:,:] = np.flip(my_solid, axis=0 )[-1*rnd_num[0]:,:,:]\n",
        "  my_aug_solid[rnd_num[0]:,:,:] = my_solid[:-1*rnd_num[0],:,:]\n",
        "\n",
        "my_solid = my_aug_solid\n",
        "my_aug_solid = np.ones_like(temp)\n",
        "\n",
        "if(rnd_num[1] < 0):\n",
        "  my_aug_solid[:,:rnd_num[1],:] = my_solid[:,-1*rnd_num[1]:,:]\n",
        "  my_aug_solid[:,rnd_num[1]:,:] = np.flip(my_solid, axis=1 )[:,:-1*rnd_num[1],:]\n",
        "else:\n",
        "  my_aug_solid[:,:rnd_num[1],:] = np.flip(my_solid, axis=1 )[:,-1*rnd_num[1]:,:]\n",
        "  my_aug_solid[:,rnd_num[1]:,:] = my_solid[:,:-1*rnd_num[1],:]\n",
        "\n",
        "plt.imshow(my_aug_solid[:,:,9])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWQUcJU4UBHm"
      },
      "outputs": [],
      "source": [
        "plt.imshow(my_solid[:,:,9])\n",
        "plt.show()\n",
        "\n",
        "rnd_num = (10,10)\n",
        "\n",
        "if(rnd_num[1] < 0):\n",
        "  my_aug_solid[:,:rnd_num[1],:] = my_solid[:,-1*rnd_num[1]:,:]\n",
        "  my_aug_solid[:,rnd_num[1]:,:] = np.flip(my_solid, axis=1 )[:,:-1*rnd_num[1],:]\n",
        "else:\n",
        "  my_aug_solid[:,:rnd_num[1],:] = np.flip(my_solid, axis=1 )[:,-1*rnd_num[1]:,:]\n",
        "  my_aug_solid[:,rnd_num[1]:,:] = my_solid[:,:-1*rnd_num[1],:]\n",
        "\n",
        "plt.imshow(my_aug_solid[:,:,9])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5cgyRwKMhY2"
      },
      "outputs": [],
      "source": [
        "temp = np.array([1,2,3,4,5,6,67,7,8,9])\n",
        "\n",
        "print(temp[:-3])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#temp = np.zeros( (20,20,20) )\n",
        "#temp[13:,13:,:] = 10\n",
        "\n",
        "temp = uc_solid[0,:,:,:]\n",
        "temp_v = uc_vel[0,:,:,:,0]\n",
        "\n",
        "plt.imshow(temp[:,:,9])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(temp_v[:,:,9])\n",
        "plt.show()\n",
        "\n",
        "my_aug_solid = np.flip(temp, axis=0)\n",
        "my_aug_vel = np.flip(-1*temp_v, axis=0)\n",
        "\n",
        "plt.imshow(my_aug_solid[:,:,9])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(my_aug_vel[:,:,9])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9tAJRGxO48hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1FdBItwuhbM"
      },
      "source": [
        "## Save training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug8X6zq28WDT"
      },
      "outputs": [],
      "source": [
        "data_num = 1\n",
        "\n",
        "np.save('Hoffman Cluster/train data/train_solid_randomsphere_data{}'.format(data_num), train_data_solid)\n",
        "np.save('Hoffman Cluster/train data/train_vel{}_randomsphere_data{}'.format(velocity_dir, data_num), train_data_vel)\n",
        "\n",
        "np.save('Hoffman Cluster/train data/val_solid_randomsphere_data{}'.format(data_num), val_data_solid)\n",
        "np.save('Hoffman Cluster/train data/val_vel{}_randomsphere_data{}'.format(velocity_dir, data_num), val_data_vel)\n",
        "\n",
        "np.save('Hoffman Cluster/train data/test_solid_randomsphere_data{}'.format(data_num), test_data_solid)\n",
        "np.save('Hoffman Cluster/train data/test_vel{}_randomsphere_data{}'.format(velocity_dir, data_num), test_data_vel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RUpwbZV9MFD"
      },
      "outputs": [],
      "source": [
        "velocity_dir = 'x'\n",
        "\n",
        "augGen_seed = 10\n",
        "aug_iter = 15\n",
        "\n",
        "train_data_solid = np.load('Hoffman Cluster/train data/train_solid_randomsphere_augGenSeed_{}_AugIter_{}.npy'.format(augGen_seed, aug_iter))\n",
        "train_data_vel = np.load('Hoffman Cluster/train data/train_vel{}_randomsphere_augGenSeed_{}_AugIter_{}.npy'.format(velocity_dir, augGen_seed, aug_iter))\n",
        "\n",
        "val_data_solid = np.load('Hoffman Cluster/train data/val_solid_randomsphere_augGenSeed_{}_AugIter_{}.npy'.format(augGen_seed, aug_iter))\n",
        "val_data_vel = np.load('Hoffman Cluster/train data/val_vel{}_randomsphere_augGenSeed_{}_AugIter_{}.npy'.format(velocity_dir, augGen_seed, aug_iter))\n",
        "\n",
        "test_data_solid = np.load('Hoffman Cluster/train data/test_solid_randomsphere_augGenSeed_{}_AugIter_{}.npy'.format(augGen_seed, aug_iter))\n",
        "test_data_vel = np.load('Hoffman Cluster/train data/test_vel{}_randomsphere_augGenSeed_{}_AugIter_{}.npy'.format(velocity_dir, augGen_seed, aug_iter))\n",
        "\n",
        "print(train_data_solid.shape)\n",
        "print(val_data_solid.shape)\n",
        "print(test_data_solid.shape)\n",
        "\n",
        "print(train_data_vel.shape)\n",
        "print(val_data_vel.shape)\n",
        "print(test_data_vel.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGzya783nltX"
      },
      "source": [
        "## Data Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBmVl8Gw7gwO"
      },
      "outputs": [],
      "source": [
        "vrange = np.linspace(0,10,100)\n",
        "vel_norm_nvoxel = np.zeros(vrange.shape[0]-1)\n",
        "\n",
        "test_data_vel_flat = test_data_vel.flatten()\n",
        "\n",
        "for i in range(vel_norm_nvoxel.shape[0]):\n",
        "\n",
        "  vel_norm_nvoxel[i] = np.sum( test_data_vel_flat[ (test_data_vel_flat >= vrange[i]) & (test_data_vel_flat < vrange[i+1]) ] )\n",
        "\n",
        "plt.bar(vrange[:-1], vel_norm_nvoxel)\n",
        "plt.xlabel('V')\n",
        "plt.ylabel('Number of voxels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lheXF-QIqJdr"
      },
      "outputs": [],
      "source": [
        "# Voxel histogram of minmax velocity\n",
        "\n",
        "percentile = np.linspace(-10,10,200)\n",
        "vel_nvoxel = np.zeros(percentile.shape[0]-1)\n",
        "\n",
        "for i in range(vel_nvoxel.shape[0]):\n",
        "\n",
        "  vel_masked = np.ma.masked_outside(uc_vel_minmax[2,:,:,:], percentile[i], percentile[i+1])\n",
        "  vel_filled = np.ma.filled(vel_masked, fill_value=0)\n",
        "  vel_nvoxel[i] = vel_filled[vel_filled != 0].shape[0]\n",
        "\n",
        "plt.bar(percentile[:-1], vel_nvoxel)\n",
        "plt.xlabel('V')\n",
        "plt.ylabel('Number of voxels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsDh6suNP0ZI"
      },
      "outputs": [],
      "source": [
        "raw_data_perm = np.zeros( (5, uc_solid.shape[0]) )\n",
        "norm_data_perm = np.zeros( (5, uc_solid.shape[0]) )\n",
        "\n",
        "x_max = 50\n",
        "res = 20e-6\n",
        "\n",
        "for i in range(raw_data_perm.shape[1]):\n",
        "  norm_data_perm[0,i] = uc_vel_minmax[i,:,:,:].mean()\n",
        "  raw_data_perm[0,i] = norm_data_perm[0,i]*x_max*(res**2)\n",
        "  raw_data_perm[1,i] = uc_vel_minmax[i,:60,:60,:].mean()*x_max*(res**2)\n",
        "  raw_data_perm[2,i] = uc_vel_minmax[i,:60,60:,:].mean()*x_max*(res**2)\n",
        "  raw_data_perm[3,i] = uc_vel_minmax[i,60:,:60,:].mean()*x_max*(res**2)\n",
        "  raw_data_perm[4,i] = uc_vel_minmax[i,60:,60:,:].mean()*x_max*(res**2)\n",
        "\n",
        "\n",
        "plt.hist(raw_data_perm[0,:], bins=20)\n",
        "plt.title('Permeability')\n",
        "plt.show()\n",
        "plt.hist(norm_data_perm[0,:], bins=20)\n",
        "plt.title('Normalized Permeability')\n",
        "plt.xlim([0.14, 0.24])\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.hist(raw_data_perm[1,:], bins=10)\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.hist(raw_data_perm[2,:], bins=10)\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.hist(raw_data_perm[3,:], bins=10)\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.hist(raw_data_perm[4,:], bins=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioiwJ_ownsQe"
      },
      "outputs": [],
      "source": [
        "train_data_perm = np.zeros( (5, train_data_solid.shape[0]) )\n",
        "train_data_norm = np.zeros( (5, train_data_solid.shape[0]) )\n",
        "\n",
        "for i in range(train_data_perm.shape[1]):\n",
        "  train_data_norm[0,i] = train_data_vel[i,:,:,:,0].mean()\n",
        "  train_data_perm[0,i] = train_data_norm[0,i]*x_max*(res**2)\n",
        "  train_data_perm[1,i] = train_data_vel[i,:60,:60,:,0].mean()*x_max*(res**2)\n",
        "  train_data_perm[2,i] = train_data_vel[i,:60,:60,:,0].mean()*x_max*(res**2)\n",
        "  train_data_perm[3,i] = train_data_vel[i,:60,:60,:,0].mean()*x_max*(res**2)\n",
        "  train_data_perm[4,i] = train_data_vel[i,:60,:60,:,0].mean()*x_max*(res**2)\n",
        "\n",
        "plt.hist(train_data_perm[0,:], bins=10)\n",
        "plt.title('Raw Permeability')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(train_data_norm[0,:], bins=10)\n",
        "plt.title('Normalized Permeability')\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.hist(train_data_perm[1,:], bins=10)\n",
        "plt.title('I')\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.hist(train_data_perm[2,:], bins=10)\n",
        "plt.title('II')\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.hist(train_data_perm[3,:], bins=10)\n",
        "plt.title('III')\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.hist(train_data_perm[4,:], bins=10)\n",
        "plt.title('IV')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQovoz5NZAXW"
      },
      "source": [
        "## Illustrations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg_xA4RJnUlI"
      },
      "outputs": [],
      "source": [
        "# Raw data\n",
        "sample_number = 2\n",
        "\n",
        "slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "fig, axs = plt.subplots( nrows=2, ncols=3,figsize=(10,10) )\n",
        "\n",
        "vel_magnitude = 1e-4\n",
        "\n",
        "for j in np.array( [0, 1, 2] ):\n",
        "  im=axs[0,j].imshow(uc_solid[sample_number,:,:,slice[j]], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[0,j],fraction=0.05)\n",
        "  axs[0,j].axis('off')\n",
        "  axs[0,j].set_title('%s Solid' % (fig_title[j]))\n",
        "\n",
        "  im=axs[1,j].imshow(uc_vel[sample_number,:,:,slice[j],0], clim=(0,vel_magnitude), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[1,j],fraction=0.05)\n",
        "  axs[1,j].axis('off')\n",
        "  axs[1,j].set_title('%s Velocity' % (fig_title[j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVNJepAZkQBw"
      },
      "outputs": [],
      "source": [
        "# Norm data\n",
        "sample_number = 0\n",
        "\n",
        "slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "fig, axs = plt.subplots( nrows=2, ncols=3,figsize=(10,10) )\n",
        "\n",
        "for j in np.array( [0, 1, 2] ):\n",
        "  im=axs[0,j].imshow(uc_solid[sample_number,:,:,slice[j]], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[0,j],fraction=0.05)\n",
        "  axs[0,j].axis('off')\n",
        "  axs[0,j].set_title('%s Solid' % (fig_title[j]))\n",
        "\n",
        "  im=axs[1,j].imshow(uc_vel_norm[sample_number,:,:,slice[j]], clim=(0,40), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[1,j],fraction=0.05)\n",
        "  axs[1,j].axis('off')\n",
        "  axs[1,j].set_title('%s Velocity' % (fig_title[j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8_ZCNi7MqRM"
      },
      "outputs": [],
      "source": [
        "# Minmax data\n",
        "sample_number = 5\n",
        "\n",
        "slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "fig, axs = plt.subplots( nrows=2, ncols=3,figsize=(10,10) )\n",
        "\n",
        "vel_magnitude = 10\n",
        "\n",
        "for j in np.array( [0, 1, 2] ):\n",
        "  im=axs[0,j].imshow(uc_solid[sample_number,:,:,slice[j]], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[0,j],fraction=0.05)\n",
        "  axs[0,j].axis('off')\n",
        "  axs[0,j].set_title('%s Solid' % (fig_title[j]))\n",
        "\n",
        "  im=axs[1,j].imshow(uc_vel_minmax[sample_number,:,:,slice[j],0], clim=(0,vel_magnitude), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[1,j],fraction=0.05)\n",
        "  axs[1,j].axis('off')\n",
        "  axs[1,j].set_title('%s Velocity' % (fig_title[j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H69fQG39pxbh"
      },
      "outputs": [],
      "source": [
        "# Data check - train data\n",
        "sample_number = 2\n",
        "\n",
        "slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "fig, axs = plt.subplots( nrows=2, ncols=3,figsize=(10,10) )\n",
        "\n",
        "for j in np.array( [0, 1, 2] ):\n",
        "  im=axs[0,j].imshow(train_data_solid[sample_number,:,:,slice[j],0], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[0,j],fraction=0.05)\n",
        "  axs[0,j].axis('off')\n",
        "  axs[0,j].set_title('%s Solid' % (fig_title[j]))\n",
        "\n",
        "  im=axs[1,j].imshow(train_data_vel[sample_number,:,:,slice[j],0], clim=(-2,2), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[1,j],fraction=0.05)\n",
        "  axs[1,j].axis('off')\n",
        "  axs[1,j].set_title('%s Velocity' % (fig_title[j]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWJHOo-z5bkj"
      },
      "source": [
        "# Darcy Unet Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unet Model"
      ],
      "metadata": {
        "id": "rXNH4Be39Hua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, BatchNormalization, Activation, Concatenate, Dropout, Multiply\n",
        "\n",
        "from numpy import floor, ceil\n",
        "\n",
        "def encoder_block(inputs, strides, filter_num, filter_size, activation, momentum, rate):\n",
        "\n",
        "  path = Conv3D(filter_num, filter_size, padding='same', strides=strides)(inputs)\n",
        "  path = BatchNormalization(momentum=momentum)(path)\n",
        "  path = Activation(activation=activation)(path)\n",
        "  path = Dropout(rate)(path)\n",
        "\n",
        "  return path\n",
        "\n",
        "\n",
        "def decoder_block(inputs, strides, filter_num, filter_size, activation, momentum, rate):\n",
        "\n",
        "  path = Conv3DTranspose(filter_num, filter_size, padding='same', strides=strides)(inputs)\n",
        "  path = BatchNormalization(momentum=momentum)(path)\n",
        "  path = Activation(activation=activation)(path)\n",
        "  path = Dropout(rate)(path)\n",
        "\n",
        "  return path\n",
        "\n",
        "\n",
        "def UnetV1(input_shape, filter_num = 5, filter_size = 3, activation = 'selu', momentum = 0.99, rate = 0.2):\n",
        "\n",
        "  inputs = Input(shape = input_shape)\n",
        "\n",
        "  skip_connection = []\n",
        "\n",
        "  for i in range(8):\n",
        "    \n",
        "    if(i <= 0):\n",
        "      path_encoder = encoder_block(inputs, 1, filter_num*(2**floor(i/2)), filter_size, activation, momentum, rate)\n",
        "    else:\n",
        "\n",
        "      if(i % 2 == 1):\n",
        "        path_encoder = encoder_block(path_encoder, 1, filter_num*(2**floor(i/2)), filter_size, activation, momentum, rate)\n",
        "        skip_connection.append(path_encoder)\n",
        "      else:\n",
        "        path_encoder = encoder_block(path_encoder, 2, filter_num*(2**floor(i/2)), filter_size, activation, momentum, rate)\n",
        "\n",
        "  for i in reversed(range(6)):\n",
        "\n",
        "    if(i >= 5):\n",
        "      path_decoder = decoder_block(path_encoder, 2, filter_num*(2**floor(i/2)), filter_size, activation, momentum, rate)\n",
        "      path_decoder = Concatenate()([ path_decoder, skip_connection[int(floor(i/2))] ])\n",
        "    else:\n",
        "\n",
        "      if(i % 2 == 0):\n",
        "        path_decoder = decoder_block(path_decoder, 1, filter_num*(2**floor(i/2)), filter_size, activation, momentum, rate)\n",
        "      else:\n",
        "        path_decoder = decoder_block(path_decoder, 2, filter_num*(2**floor(i/2)), filter_size, activation, momentum, rate)\n",
        "        path_decoder = Concatenate()([ path_decoder, skip_connection[int(floor(i/2))] ])\n",
        "\n",
        "\n",
        "  path = Conv3D(filter_num, filter_size, padding='same')(path_decoder)\n",
        "  path = Conv3D(1, 1, padding='same')(path)\n",
        "\n",
        "  #for version 2\n",
        "  #path = Multiply()([inputs, path])\n",
        "\n",
        "  return Model(inputs=inputs, outputs=path)\n",
        "\n",
        "\n",
        "def UnetV2(input_shape, x_model, y_model, z_model, filter_num = 5, filter_size = 3, activation = 'selu', momentum = 0.99, rate = 0.2):\n",
        "\n",
        "  v_scale = 1\n",
        "  \n",
        "  inputs = Input(shape = input_shape)\n",
        "\n",
        "  x_input = tf.math.multiply( x_model(inputs, training=False), 0.5*v_scale )\n",
        "  y_input = tf.math.multiply( y_model(inputs, training=False), 0.5*v_scale )\n",
        "  z_input = tf.math.multiply( z_model(inputs, training=False), 1*v_scale )\n",
        "\n",
        "  path = Concatenate()( [x_input, y_input, z_input] )\n",
        "\n",
        "  skip_connection = []\n",
        "\n",
        "  for i in range(8):\n",
        "  \n",
        "    if(i <= 0):\n",
        "      path_encoder = encoder_block(path, 1, filter_num, filter_size, activation, momentum, rate)\n",
        "    else:\n",
        "\n",
        "      if(i % 2 == 1):\n",
        "        path_encoder = encoder_block(path_encoder, 1, filter_num, filter_size, activation, momentum, rate)\n",
        "        skip_connection.append(path_encoder)\n",
        "      else:\n",
        "        path_encoder = encoder_block(path_encoder, 2, filter_num, filter_size, activation, momentum, rate)\n",
        "\n",
        "  for i in reversed(range(6)):\n",
        "\n",
        "    if(i >= 5):\n",
        "      path_decoder = decoder_block(path_encoder, 2, filter_num, filter_size, activation, momentum, rate)\n",
        "      path_decoder = Concatenate()([ path_decoder, skip_connection[int(floor(i/2))] ])\n",
        "    else:\n",
        "\n",
        "      if(i % 2 == 0):\n",
        "        path_decoder = decoder_block(path_decoder, 1, filter_num, filter_size, activation, momentum, rate)\n",
        "      else:\n",
        "        path_decoder = decoder_block(path_decoder, 2, filter_num, filter_size, activation, momentum, rate)\n",
        "        path_decoder = Concatenate()([ path_decoder, skip_connection[int(floor(i/2))] ])\n",
        "\n",
        "\n",
        "  path = Conv3D(filter_num, filter_size, padding='same')(path_decoder)\n",
        "  path = Conv3D(3, 1, padding='same')(path)\n",
        "\n",
        "  return Model(inputs=inputs, outputs=path)"
      ],
      "metadata": {
        "id": "FIoCt9zj9G4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1GLAmqe9H5q"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJpvXd9zL3vG"
      },
      "outputs": [],
      "source": [
        "version = 'Z1-4-Seed3'\n",
        "\n",
        "model_name = 'UnetRS_Modelv{}'.format(version)\n",
        "\n",
        "dir_save   = 'RandomSphere Model/{}'.format(model_name)\n",
        "try:\n",
        "  os.mkdir(dir_save)\n",
        "except OSError as error:\n",
        "  print(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH1QlPVXMZ3J"
      },
      "outputs": [],
      "source": [
        "filter_size = 4\n",
        "num_filters = 10\n",
        "\n",
        "learning_rate = 0.0006\n",
        "batch_size    = 4\n",
        "\n",
        "momentum = 0.9\n",
        "rate = 0.1\n",
        "\n",
        "epochs        = 1000\n",
        "patience_training = 50\n",
        "\n",
        "metrics=['MAE', 'MSE']\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "\n",
        "model = UnetV1( input_shape = (data_size, data_size, data_size, 1), filter_num = num_filters, filter_size = filter_size, activation = 'selu', momentum = momentum, rate = rate)\n",
        "\n",
        "#model.summary(line_length = 250)\n",
        "\n",
        "model.compile( loss = tf.keras.losses.mean_squared_error, optimizer=optimizer, metrics=metrics[:] )\n",
        "\n",
        "nan_terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "early_stop    = tf.keras.callbacks.EarlyStopping(monitor ='val_loss', min_delta = 0,\n",
        "                                              patience = patience_training, \n",
        "                                              verbose = True, mode = 'auto', baseline = None)\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(\"{}/training_log_{}.csv\".format(dir_save,model_name))\n",
        "\n",
        "checkpoint = ModelCheckpoint('{}/{}.ckpt'.format(dir_save,model_name), \n",
        "                             monitor = 'val_loss', \n",
        "                             verbose = 1, \n",
        "                             save_best_only = True, \n",
        "                             mode = 'min', save_weights_only = False)\n",
        "\n",
        "callbacks_list = [nan_terminate,\n",
        "                  early_stop,\n",
        "                  checkpoint,\n",
        "                  csv_logger]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du4uqKrn67Os"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "imgtype = ('LR','TB')\n",
        "for i in imgtype:\n",
        "  plot_model(model, to_file='RandomSphere Model/Model Image/{}_{}.jpg'.format(model_name, i), rankdir = i, show_layer_names = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1WG4Z7mAlOH"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "from datetime import timedelta\n",
        "\n",
        "start = timer()\n",
        "\n",
        "model.fit( x = train_data_solid, y = train_data_vel, \n",
        "           epochs = epochs, batch_size = batch_size,\n",
        "           validation_data = (val_data_solid, val_data_vel),\n",
        "           validation_freq = 1,\n",
        "           verbose = 1,\n",
        "           callbacks = callbacks_list)\n",
        "\n",
        "end = timer()\n",
        "print('Elapsed time for training : {}'.format(timedelta(seconds=end-start)))   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XYZ Model Training"
      ],
      "metadata": {
        "id": "QVvmsf2yJYmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version = 'XYZ1-8-Seed3'\n",
        "\n",
        "model_name = 'UnetRSXYZ_Modelv{}'.format(version)\n",
        "\n",
        "dir_save   = 'RandomSphere XYZ Model/{}'.format(model_name)\n",
        "try:\n",
        "  os.mkdir(dir_save)\n",
        "except OSError as error:\n",
        "  print(error)"
      ],
      "metadata": {
        "id": "1DCF9fImJb0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_size = 3\n",
        "num_filters = 9\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size    = 4\n",
        "\n",
        "momentum = 0.99\n",
        "rate = 0.0001\n",
        "\n",
        "epochs        = 1000\n",
        "patience_training = 50\n",
        "\n",
        "metrics=['MAE', 'MSE']\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "\n",
        "\n",
        "version_x = 'X1-3'\n",
        "x_model_name = 'UnetRS_Modelv{}'.format(version_x)\n",
        "x_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(x_model_name, x_model_name ) )\n",
        "x_model._name = 'xmodel'\n",
        "x_model.trainable = False\n",
        "\n",
        "version_y = 'Y1-1'\n",
        "y_model_name = 'UnetRS_Modelv{}'.format(version_y)\n",
        "y_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(y_model_name, y_model_name ) )\n",
        "y_model._name = 'ymodel'\n",
        "y_model.trainable = False\n",
        "\n",
        "version_z = 'Z1-4'\n",
        "z_model_name = 'UnetRS_Modelv{}'.format(version_z)\n",
        "z_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(z_model_name, z_model_name ) )\n",
        "z_model._name = 'zmodel'\n",
        "z_model.trainable = False\n",
        "\n",
        "model = UnetV2( input_shape = (data_size, data_size, data_size, 1), x_model = x_model, y_model = y_model, z_model = z_model,\n",
        "                filter_num = num_filters, filter_size = filter_size, activation = 'selu', momentum = momentum, rate = rate)\n",
        "\n",
        "#model.summary(line_length = 250)\n",
        "\n",
        "#model.compile( loss = tf.keras.losses.mean_squared_error, optimizer=optimizer, metrics=metrics[:] )\n",
        "model.compile( loss = div_loss2, optimizer=optimizer, metrics=metrics[:])\n",
        "\n",
        "nan_terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "early_stop    = tf.keras.callbacks.EarlyStopping(monitor ='val_loss', min_delta = 0,\n",
        "                                              patience = patience_training, \n",
        "                                              verbose = True, mode = 'auto', baseline = None)\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(\"{}/training_log_{}.csv\".format(dir_save,model_name))\n",
        "\n",
        "checkpoint = ModelCheckpoint('{}/{}.ckpt'.format(dir_save,model_name), \n",
        "                             monitor = 'val_loss', \n",
        "                             verbose = 1, \n",
        "                             save_best_only = True, \n",
        "                             mode = 'min', save_weights_only = False)\n",
        "\n",
        "callbacks_list = [nan_terminate,\n",
        "                  early_stop,\n",
        "                  checkpoint,\n",
        "                  csv_logger]"
      ],
      "metadata": {
        "id": "Z3eIT-QFJetI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "imgtype = ('LR','TB')\n",
        "for i in imgtype:\n",
        "  plot_model(model, to_file='RandomSphere Model/Model Image/{}_{}.jpg'.format(model_name, i), rankdir = i, show_layer_names = False)"
      ],
      "metadata": {
        "id": "edjpGUXhJf5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "from datetime import timedelta\n",
        "\n",
        "start = timer()\n",
        "\n",
        "model.fit( x = train_data_solid, y = train_data_vel, \n",
        "           epochs = epochs, batch_size = batch_size,\n",
        "           validation_data = (val_data_solid, val_data_vel),\n",
        "           validation_freq = 1,\n",
        "           verbose = 1,\n",
        "           callbacks = callbacks_list)\n",
        "\n",
        "end = timer()\n",
        "print('Elapsed time for training : {}'.format(timedelta(seconds=end-start)))   "
      ],
      "metadata": {
        "id": "r_6aa5SjJg1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eT5HRwnOo1N"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrEcplSANPCa"
      },
      "outputs": [],
      "source": [
        "#version = 'Z1-4'\n",
        "#eval_model_name = 'UnetRS_Modelv{}'.format(version)\n",
        "#eval_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(eval_model_name, eval_model_name ) )\n",
        "\n",
        "version = 'XYZ1-0'\n",
        "eval_model_name = 'UnetRSXYZ_Modelv{}'.format(version)\n",
        "eval_model = tf.keras.models.load_model( 'RandomSphere XYZ Model/{}/{}.ckpt'.format(eval_model_name, eval_model_name ) )\n",
        "#eval_model = tf.keras.models.load_model( 'RandomSphere XYZ Model/{}/{}.ckpt'.format(eval_model_name, eval_model_name ), custom_objects = {'div_loss2': div_loss2} )\n",
        "\n",
        "for i in range(test_data_solid.shape[0]):\n",
        "  print('\\nSample number : {}'.format(i+1))\n",
        "  eval_model.evaluate(test_data_solid[i:i+1,:,:,:,:], test_data_vel[i:i+1,:,:,:,:])\n",
        "\n",
        "vz_test_pred = np.float32( eval_model.predict( x=[test_data_solid] ) )\n",
        "\n",
        "print(vz_test_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di3Z8wZyToPV"
      },
      "outputs": [],
      "source": [
        "# Overall Permeability\n",
        "\n",
        "perm_true = test_data_vel[:,:,:,:,2].mean(axis=(1,2,3))\n",
        "perm_pred = vz_test_pred[:,:,:,:,2].mean(axis=(1,2,3))\n",
        "\n",
        "perm_error = abs( perm_true - perm_pred )/abs(perm_true)*100\n",
        "\n",
        "print( 'Overall permeability error : {:.3f}\\n'.format(perm_error.mean()) )\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(np.arange(perm_error.shape[0]), perm_error)\n",
        "plt.title('Permeability Error')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(np.arange(perm_error.shape[0]),test_data_vel[:,:,:,:,0].mean(axis=(1,2,3)))\n",
        "plt.title('Average velocity')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "\n",
        "print(perm_error)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voxel-wise MAPE Absolute value velocity\n",
        "v_max = 5\n",
        "channel = 2\n",
        "\n",
        "vel_true_flat = test_data_vel[:,:,:,:,channel].flatten()\n",
        "vel_pred_flat = vz_test_pred[:,:,:,:,channel].flatten()\n",
        "\n",
        "v_range = np.linspace(0.0001,v_max,100)\n",
        "\n",
        "vel_true_flat_nonzero = vel_true_flat[ (vel_true_flat < 0) | (vel_true_flat > 0)]\n",
        "vel_pred_flat_nonzero = vel_pred_flat[ (vel_true_flat < 0) | (vel_true_flat > 0)] \n",
        "\n",
        "vel_mape_flat = (vel_true_flat_nonzero - vel_pred_flat_nonzero)/vel_true_flat_nonzero*100\n",
        "\n",
        "plt.plot(vel_true_flat_nonzero, vel_mape_flat,'bo',markersize=0.1,figure=plt.figure(figsize=[8,6]))\n",
        "plt.ylim(-100,100)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "vel_mape_flat_range = np.zeros_like(v_range)\n",
        "\n",
        "for i in range(v_range.shape[0]-1):\n",
        "  if(v_range[i] != 0):\n",
        "    vel_mape_flat_vrange = np.abs( vel_mape_flat[ (np.abs(vel_true_flat_nonzero) > v_range[i]) & (np.abs(vel_true_flat_nonzero) < v_range[i+1]) ] )\n",
        "\n",
        "  if(vel_mape_flat_vrange.shape[0] > 0):\n",
        "    vel_mape_flat_range[i] = np.mean(vel_mape_flat_vrange)\n",
        "\n",
        "plt.plot(v_range[:-1], vel_mape_flat_range[:-1], 'bo',markersize=4,figure=plt.figure(figsize=[8,6]))\n",
        "plt.ylim(0,100)\n",
        "plt.xlabel('velocity')\n",
        "plt.ylabel('% error')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "threshold = 9.17/x_max\n",
        "\n",
        "vel_mape_flat_threshold = vel_mape_flat[ (vel_true_flat_nonzero <= (-1*threshold)) | (vel_true_flat_nonzero >= (1*threshold)) ]\n",
        "print(\"% Error above threshold : {}\".format(np.mean(vel_mape_flat_threshold[vel_mape_flat_threshold > 0])))\n",
        "\n",
        "#print(v_range)\n",
        "#print(vel_mape_flat_range)"
      ],
      "metadata": {
        "id": "zIqRESdXFiab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVgHQ_i84Gl_"
      },
      "outputs": [],
      "source": [
        "test_sample = 1\n",
        "print( 'Maximum Sample Number : {}'.format(test_data_solid.shape[0] - 1) )\n",
        "\n",
        "mySolid = test_data_solid[test_sample,:,:,:,0]\n",
        "mySolid_mask = np.ma.masked_less(mySolid,1)\n",
        "\n",
        "myVel_true = test_data_vel[test_sample,:,:,:,2]\n",
        "myVel_true = np.ma.array( myVel_true, mask=np.ma.getmask(mySolid_mask) )\n",
        "\n",
        "myVel_pred = vz_test_pred[test_sample,:,:,:,2]\n",
        "myVel_pred = np.ma.array( myVel_pred, mask=np.ma.getmask(mySolid_mask) )\n",
        "\n",
        "myVel_true = myVel_true*x_max\n",
        "myVel_pred = myVel_pred*x_max\n",
        "\n",
        "test_slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "fig, axs = plt.subplots( nrows=3, ncols=3,figsize=(20,20) )\n",
        "\n",
        "vel_range = (0,50)\n",
        "\n",
        "for j in range(3):\n",
        "\n",
        "  im=axs[j,0].imshow(mySolid[:,:,test_slice[j]], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[j,0],fraction=0.05)\n",
        "  axs[j,0].axis('off')\n",
        "  #axs[j,0].set_title('{} Solid'.format(fig_title[j]))\n",
        "\n",
        "  im=axs[j,1].imshow(myVel_true[:,:,test_slice[j]], clim=vel_range, cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[j,1],fraction=0.05)\n",
        "  axs[j,1].axis('off')\n",
        "  #axs[j,1].set_title('{} Simulation'.format(fig_title[j]))\n",
        "\n",
        "  im=axs[j,2].imshow(myVel_pred[:,:,test_slice[j]], clim=vel_range, cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[j,2],fraction=0.05)\n",
        "  axs[j,2].axis('off')\n",
        "  #axs[j,2].set_title('{} Prediction'.format(fig_title[j]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div = np.zeros( (vz_test_pred.shape[0],118,118,118) )\n",
        "for i in range(vz_test_pred.shape[0]):\n",
        "\n",
        "  temp_vel = vz_test_pred[i,:,:,:,:]\n",
        "\n",
        "  dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "  dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "  dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "  div[i,:,:,:] = dVxdx + dVydy + dVzdz\n",
        "\n",
        "print( np.mean( np.abs(div), axis=(1,2,3)) )\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.1,0.1,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ))"
      ],
      "metadata": {
        "id": "Cx1D3WIpZMS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temp_vel = vz_test_pred[0,:,:,:,:]*test_data_solid[0,:,:,:,:]\n",
        "temp_vel = vz_test_pred[0,:,:,:,:]\n",
        "\n",
        "dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "div = dVxdx + dVydy + dVzdz\n",
        "\n",
        "plt.imshow(test_data_solid[0,:,:,59,0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(temp_vel[:,:,59,2])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(div[:,:,59])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.1,0.1,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ))"
      ],
      "metadata": {
        "id": "2l8k5PYs6szg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_vel = test_data_vel[0,:,:,:,:]\n",
        "\n",
        "dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "div = dVxdx + dVydy + dVzdz\n",
        "\n",
        "plt.imshow(test_data_solid[0,:,:,5,0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(temp_vel[:,:,5,2])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(div[:,:,5])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.1,0.1,100))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4iHCVuLK7WoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmYWthb6oeI9"
      },
      "source": [
        "## Evaluate SiC Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3EVagtO6mBE"
      },
      "source": [
        "### Load SiC Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mMqVsKmojuJ"
      },
      "outputs": [],
      "source": [
        "sic_dir_data = 'Data/SiC Data'\n",
        "data_size = 120\n",
        "\n",
        "denRange = [45, 65, 80]\n",
        "domainRange = [1, 2]\n",
        "\n",
        "# X : 'x'\n",
        "# Y : 'y'\n",
        "# Z : ''\n",
        "#velocity_dir = ('x')\n",
        "#velocity_dir = ('y')\n",
        "#velocity_dir = ('z')\n",
        "velocity_dir = ('x', 'y', 'z')\n",
        "\n",
        "channel_size = len(velocity_dir)\n",
        "\n",
        "sic_solid = np.zeros( (1,data_size,data_size,data_size,1) )\n",
        "sic_vel = np.zeros( (1,data_size,data_size,data_size,channel_size) )\n",
        "\n",
        "for i in range(len(denRange)):\n",
        "  for j in range(len(domainRange)):\n",
        "\n",
        "    sic_solid_load = loadmat( '{}/{}PPI_domain{}_deci.mat'.format(sic_dir_data, denRange[i], domainRange[j]) )['solid'].astype('int')\n",
        "    sic_solid_load = sic_solid_load <= 0\n",
        "    sic_solid = np.append( sic_solid, np.expand_dims(sic_solid_load, axis=(0,-1)), axis=0 )\n",
        "\n",
        "    sic_vel_load = np.zeros( (1,data_size,data_size,data_size,channel_size))\n",
        "    for k in range(channel_size):\n",
        "      if(velocity_dir[k] == 'z'):\n",
        "        sic_vel_load[0,:,:,:,k] = loadmat( '{}/{}PPI_domain{}_vfield{}.mat'.format(sic_dir_data, denRange[i], domainRange[j], '') )['vfield'].astype('float32')\n",
        "      else:\n",
        "        sic_vel_load[0,:,:,:,k] = loadmat( '{}/{}PPI_domain{}_vfield{}.mat'.format(sic_dir_data, denRange[i], domainRange[j], velocity_dir[k]) )['vfield'].astype('float32')\n",
        "\n",
        "    sic_vel = np.append( sic_vel, sic_vel_load, axis=0 )\n",
        "\n",
        "sic_solid = sic_solid[1:,:,:,:]\n",
        "sic_vel = sic_vel[1:,:,:,:]\n",
        "\n",
        "print('Image size : {}\\nNumber of Data : {}  {}'.format(data_size, sic_solid.shape, sic_vel.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39o_LzeQSf4B"
      },
      "outputs": [],
      "source": [
        "\"\"\" Normalization\n",
        "\"\"\"\n",
        "\n",
        "res = 26.708e-6\n",
        "res2 = res/2\n",
        "\n",
        "x_min = 0\n",
        "x_max = 8\n",
        "\n",
        "sic_vel_norm = sic_vel[:4,:,:,:,:]/(res**2)*0.333/9270\n",
        "sic_vel_norm = np.append(sic_vel_norm,sic_vel[4:,:,:,:,:]/(res2**2)*0.333/9270,axis=0)\n",
        "\n",
        "print( '\\nMean velocity : {}'.format( sic_vel_norm.mean() ) )\n",
        "print( '\\nMin velocity : {}'.format( sic_vel_norm.min() ) )\n",
        "print( '\\nMax velocity : {}'.format( sic_vel_norm.max() ) )\n",
        "\n",
        "sic_vel_minmax = minmax_transform(sic_vel_norm, x_min=x_min, x_range=x_max-x_min)\n",
        "\n",
        "print( '\\nMean velocity : {}'.format( sic_vel_minmax.mean() ) )\n",
        "print( '\\nMin velocity : {}'.format( sic_vel_minmax.min() ) )\n",
        "print( '\\nMax velocity : {}'.format( sic_vel_minmax.max() ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32c-jJkHxlfp"
      },
      "source": [
        "### SiC Data check"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_num = 1\n",
        "\n",
        "np.save('Data/SiC Data/sic_solid_{}'.format(data_num), sic_solid)"
      ],
      "metadata": {
        "id": "-HCCpA8c2tkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vrange = np.linspace(-30,30,200)\n",
        "vel_norm_nvoxel = np.zeros(vrange.shape[0]-1)\n",
        "\n",
        "sic_vel_norm_flat = sic_vel_norm.flatten()\n",
        "\n",
        "for i in range(vel_norm_nvoxel.shape[0]):\n",
        "\n",
        "  vel_norm_nvoxel[i] = np.abs( np.sum( sic_vel_norm_flat[ (sic_vel_norm_flat >= vrange[i]) & (sic_vel_norm_flat < vrange[i+1]) ] ) )\n",
        "\n",
        "plt.bar(vrange[:-1], vel_norm_nvoxel)\n",
        "plt.xlabel('V')\n",
        "plt.ylabel('Number of voxels')\n",
        "plt.show()\n",
        "\n",
        "print(np.sum(sic_vel_norm_flat[sic_vel_norm_flat >= 25]))"
      ],
      "metadata": {
        "id": "gYgzq8Nq-hNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpwpjQvq83Ox"
      },
      "outputs": [],
      "source": [
        "percentile = np.linspace(-5,5,100)\n",
        "vel_norm_nvoxel = np.zeros(percentile.shape[0]-1)\n",
        "\n",
        "for i in range(vel_norm_nvoxel.shape[0]):\n",
        "\n",
        "  vel_norm_masked = np.ma.masked_outside(sic_vel_minmax, percentile[i], percentile[i+1])\n",
        "  vel_norm_filled = np.ma.filled(vel_norm_masked, fill_value=0)\n",
        "  vel_norm_nvoxel[i] = vel_norm_filled[vel_norm_filled != 0].shape[0]\n",
        "\n",
        "plt.bar(percentile[:-1], vel_norm_nvoxel)\n",
        "plt.xlabel('V')\n",
        "plt.ylabel('Number of voxels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA6prInM2rhf"
      },
      "outputs": [],
      "source": [
        "raw_sic_perm = np.zeros( (5, sic_solid.shape[0]) )\n",
        "norm_sic_perm = np.zeros( (5, sic_solid.shape[0]) )\n",
        "\n",
        "x_max = 50\n",
        "res = 26.708e-6\n",
        "\n",
        "for i in range(raw_sic_perm.shape[1]):\n",
        "  norm_sic_perm[0,i] = sic_vel_minmax[i,:,:,:].mean()\n",
        "  raw_sic_perm[0,i] = norm_sic_perm[0,i]*x_max*(res**2)\n",
        "\n",
        "plt.hist(raw_sic_perm[0,:], bins=20)\n",
        "plt.title('Raw Permeability')\n",
        "plt.show()\n",
        "plt.hist(norm_sic_perm[0,:], bins=20)\n",
        "plt.title('Normalized Permeability')\n",
        "plt.xlim([0.1, 0.24])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeNR7wzSfNDk"
      },
      "outputs": [],
      "source": [
        "# Data check\n",
        "sample_number = 5\n",
        "\n",
        "slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "v_max = 9\n",
        "\n",
        "fig, axs = plt.subplots( nrows=2, ncols=3,figsize=(10,10) )\n",
        "\n",
        "for j in np.array( [0, 1, 2] ):\n",
        "  im=axs[0,j].imshow(sic_solid[sample_number,:,:,slice[j],0], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[0,j],fraction=0.05)\n",
        "  axs[0,j].axis('off')\n",
        "  axs[0,j].set_title('%s Solid' % (fig_title[j]))\n",
        "\n",
        "  im=axs[1,j].imshow(sic_vel_minmax[sample_number,:,:,slice[j],0], clim=(0,v_max), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[1,j],fraction=0.05)\n",
        "  axs[1,j].axis('off')\n",
        "  axs[1,j].set_title('%s Velocity' % (fig_title[j]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEpbeyG4xn2A"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NoWvw5ccgHM"
      },
      "outputs": [],
      "source": [
        "case_num = 3\n",
        "\n",
        "if(case_num == 1):\n",
        "  version = 'Z1-4'\n",
        "  eval_model_name = 'UnetRS_Modelv{}'.format(version)\n",
        "  eval_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(eval_model_name, eval_model_name ) )\n",
        "\n",
        "elif(case_num == 2):\n",
        "  version = 'XYZ1-0'\n",
        "  eval_model_name = 'UnetRSXYZ_Modelv{}'.format(version)\n",
        "  eval_model = tf.keras.models.load_model( 'RandomSphere XYZ Model/{}/{}.ckpt'.format(eval_model_name, eval_model_name ) )\n",
        "\n",
        "elif(case_num == 3):\n",
        "  version = 'XYZ1-8'\n",
        "  eval_model_name = 'UnetRSXYZ_Modelv{}'.format(version)\n",
        "  eval_model = tf.keras.models.load_model( 'RandomSphere XYZ Model/{}/{}.ckpt'.format(eval_model_name, eval_model_name ), custom_objects = {'div_loss2': div_loss2} )\n",
        "\n",
        "\"\"\"\n",
        "for i in range(sic_solid.shape[0]):\n",
        "  print('Sample number : {}'.format(i+1))\n",
        "  eval_model.evaluate(sic_solid[i:i+1,:,:,:,:], sic_vel_minmax[i:i+1,:,:,:,:])\n",
        "\"\"\"\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from datetime import timedelta\n",
        "\n",
        "start = timer()\n",
        "vz_test_pred = np.float32( eval_model.predict( x=[sic_solid] ) )\n",
        "end = timer()\n",
        "print('Elapsed time : {}'.format(timedelta(seconds=end-start)))\n",
        "\n",
        "print(vz_test_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model.save('Saved Model/{}'.format(eval_model_name))"
      ],
      "metadata": {
        "id": "dyAsO5KgLYpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snq6KjTdyE0B"
      },
      "outputs": [],
      "source": [
        "# Overall Permeability\n",
        "\n",
        "perm_true = sic_vel_minmax[:,:,:,:,2].mean(axis=(1,2,3))\n",
        "perm_pred = vz_test_pred[:,:,:,:,2].mean(axis=(1,2,3))\n",
        "\n",
        "perm_error = abs( (perm_true - perm_pred)/perm_true )*100\n",
        "\n",
        "print( 'Overall permeability error : {:.3f}\\n'.format(perm_error.mean()) )\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(np.arange(perm_error.shape[0]),perm_error)\n",
        "plt.title('Permeability Error')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(np.arange(perm_error.shape[0]), vz_test_pred[:,:,:,:].mean(axis=(1,2,3,4)))\n",
        "plt.title('Average velocity')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "print(perm_error)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voxel-wise MAPE Absolute value velocity\n",
        "v_max = 2\n",
        "channel = 2\n",
        "\n",
        "vel_true_flat = sic_vel_minmax[:,:,:,:,channel].flatten()\n",
        "vel_pred_flat = vz_test_pred[:,:,:,:,channel].flatten()\n",
        "\n",
        "v_range = np.linspace(0.0001,v_max,100)\n",
        "\n",
        "vel_true_flat_nonzero = vel_true_flat[ (vel_true_flat < 0) | (vel_true_flat > 0)]\n",
        "vel_pred_flat_nonzero = vel_pred_flat[ (vel_true_flat < 0) | (vel_true_flat > 0)] \n",
        "\n",
        "vel_mape_flat = (vel_true_flat_nonzero - vel_pred_flat_nonzero)/vel_true_flat_nonzero*100\n",
        "\n",
        "plt.plot(vel_true_flat_nonzero, vel_mape_flat,'bo',markersize=0.1,figure=plt.figure(figsize=[8,6]))\n",
        "plt.ylim(-100,100)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "vel_mape_flat_range = np.zeros_like(v_range)\n",
        "\n",
        "for i in range(v_range.shape[0]-1):\n",
        "  if(v_range[i] != 0):\n",
        "    vel_mape_flat_vrange = np.abs( vel_mape_flat[ (np.abs(vel_true_flat_nonzero) > v_range[i]) & (np.abs(vel_true_flat_nonzero) < v_range[i+1]) ] )\n",
        "\n",
        "  if(vel_mape_flat_vrange.shape[0] > 0):\n",
        "    vel_mape_flat_range[i] = np.mean(vel_mape_flat_vrange)\n",
        "\n",
        "plt.plot(v_range[:-1], vel_mape_flat_range[:-1], 'bo',markersize=4,figure=plt.figure(figsize=[8,6]))\n",
        "plt.ylim(0,100)\n",
        "plt.xlabel('velocity')\n",
        "plt.ylabel('% error')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "threshold = 8.93/x_max\n",
        "\n",
        "vel_mape_flat_threshold = vel_mape_flat[ (vel_true_flat_nonzero <= (-1*threshold)) | (vel_true_flat_nonzero >= (1*threshold)) ]\n",
        "print(\"% Error above threshold : {}\".format(np.mean(vel_mape_flat_threshold[vel_mape_flat_threshold > 0])))\n",
        "\n",
        "#print(v_range)\n",
        "#print(vel_mape_flat_range)"
      ],
      "metadata": {
        "id": "3qADLABvAR8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochLj88Hc-UE"
      },
      "outputs": [],
      "source": [
        "test_sample = 5\n",
        "print( 'Maximum Sample Number : {}'.format(sic_solid.shape[0] - 1) )\n",
        "\n",
        "mySolid = sic_solid[test_sample,:,:,:,0]\n",
        "mySolid_mask = np.ma.masked_less(mySolid, 1)\n",
        "\n",
        "myVel_true = sic_vel_minmax[test_sample,:,:,:,2]\n",
        "myVel_true = np.ma.array( myVel_true, mask=np.ma.getmask(mySolid_mask) )\n",
        "\n",
        "myVel_pred = vz_test_pred[test_sample,:,:,:,2]\n",
        "myVel_pred = np.ma.array( myVel_pred, mask=np.ma.getmask(mySolid_mask) )\n",
        "\n",
        "myVel_true = myVel_true*x_max\n",
        "myVel_pred = myVel_pred*x_max\n",
        "\n",
        "test_slice = np.array( [0, 59, -1] )\n",
        "fig_title = ['Inlet', 'Midpoint', 'Outlet']\n",
        "\n",
        "fig, axs = plt.subplots( nrows=3, ncols=3,figsize=(20,20) )\n",
        "\n",
        "vel_range = (0,40)\n",
        "\n",
        "for j in range(3):\n",
        "\n",
        "  im=axs[j,0].imshow(mySolid[:,:,test_slice[j]], clim=(0,1), cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[j,0],fraction=0.05)\n",
        "  axs[j,0].axis('off')\n",
        "  #axs[j,0].set_title('{} Solid'.format(fig_title[j]))\n",
        "\n",
        "  im=axs[j,1].imshow(myVel_true[:,:,test_slice[j]], clim=vel_range, cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[j,1],fraction=0.05)\n",
        "  axs[j,1].axis('off')\n",
        "  #axs[j,1].set_title('{} Simulation'.format(fig_title[j]))\n",
        "\n",
        "  im=axs[j,2].imshow(myVel_pred[:,:,test_slice[j]], clim=vel_range, cmap=plt.cm.hot)\n",
        "  fig.colorbar(im,ax=axs[j,2],fraction=0.05)\n",
        "  axs[j,2].axis('off')\n",
        "  #axs[j,2].set_title('{} Prediction'.format(fig_title[j]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div = np.zeros( (vz_test_pred.shape[0],118,118,118) )\n",
        "for i in range(vz_test_pred.shape[0]):\n",
        "\n",
        "  temp_vel = vz_test_pred[i,:,:,:,:]\n",
        "\n",
        "  dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "  dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "  dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "  div[i,:,:,:] = dVxdx + dVydy + dVzdz\n",
        "\n",
        "print( np.mean( np.abs(div), axis=(1,2,3)) )\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.1,0.1,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ))"
      ],
      "metadata": {
        "id": "quYI5i_oaDY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "version_x = 'X1-3'\n",
        "x_model_name = 'UnetRS_Modelv{}'.format(version_x)\n",
        "x_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(x_model_name, x_model_name ) )\n",
        "x_model._name = 'xmodel'\n",
        "x_model.trainable = False\n",
        "\n",
        "version_y = 'Y1-1'\n",
        "y_model_name = 'UnetRS_Modelv{}'.format(version_y)\n",
        "y_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(y_model_name, y_model_name ) )\n",
        "y_model._name = 'ymodel'\n",
        "y_model.trainable = False\n",
        "\n",
        "version_z = 'Z1-4'\n",
        "z_model_name = 'UnetRS_Modelv{}'.format(version_z)\n",
        "z_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(z_model_name, z_model_name ) )\n",
        "z_model._name = 'zmodel'\n",
        "z_model.trainable = False\n",
        "\n",
        "vx_test_pred = np.float32( x_model.predict( x=[sic_solid] ) )/2\n",
        "vy_test_pred = np.float32( y_model.predict( x=[sic_solid] ) )/2\n",
        "vz_test_pred = np.float32( z_model.predict( x=[sic_solid] ) )\n",
        "\n",
        "vz_test_pred = np.append(vx_test_pred, np.append(vy_test_pred, vz_test_pred,axis=-1),axis=-1 )\n",
        "print(vz_test_pred.shape)"
      ],
      "metadata": {
        "id": "vKrLgrihWsve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div = np.zeros( (vz_test_pred.shape[0],118,118,118) )\n",
        "for i in range(vz_test_pred.shape[0]):\n",
        "\n",
        "  temp_vel = vz_test_pred[i,:,:,:,:]\n",
        "\n",
        "  dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "  dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "  dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "  div[i,:,:,:] = dVxdx + dVydy + dVzdz\n",
        "\n",
        "print( np.mean( np.abs(div), axis=(1,2,3)) )\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.1,0.1,100))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gxWN-8vPW_tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMIXsiodIksX"
      },
      "source": [
        "### Save prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfCaWSFrImjD"
      },
      "outputs": [],
      "source": [
        "save_index = 0\n",
        "case_name = '45PPI_domain1_vfield{}'.format(velocity_dir)\n",
        "\n",
        "scipy.io.savemat( 'Prediction/{}.mat'.format(case_name), {'vfield_ML': vz_test_pred[save_index,:,:,:]} ) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Individual Model\n",
        "case_name = (45, 65, 80)\n",
        "\n",
        "for i in range(6):\n",
        "  save_name = '{}PPI_domain{}_vfield{}'.format(case_name[i//2], i%2+1, velocity_dir)\n",
        "  scipy.io.savemat( 'Prediction/UnetRS_Model/{}.mat'.format(save_name), {'vfield_ML': np.squeeze( vz_test_pred[i,:,:,:,:] )} )"
      ],
      "metadata": {
        "id": "q8mWs2T_qPxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive Model\n",
        "case_name = (45, 65, 80)\n",
        "vel_dir_save = ('x', 'y', '')\n",
        "\n",
        "for i in range(6):\n",
        "  for j in range(3):\n",
        "    save_name = '{}PPI_domain{}_vfield{}'.format(case_name[i//2], i%2+1, vel_dir_save[j])\n",
        "    scipy.io.savemat( 'Prediction/UnetRS_Model/{}.mat'.format(save_name), {'vfield_ML': np.squeeze(vz_test_pred[i,:,:,:,j]) } )"
      ],
      "metadata": {
        "id": "sbr1ZdFxiQyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divergence check"
      ],
      "metadata": {
        "id": "HuY532xA0ry8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sic_solid_temp = sic_solid[1:2,:,:,:,:]\n",
        "temp_vel = sic_vel_minmax[1,:,:,:,:]\n",
        "\n",
        "dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "div = dVxdx + dVydy + dVzdz\n",
        "\n",
        "\n",
        "plt.imshow(sic_solid_temp[0,:,:,59,0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(temp_vel[:,:,59,2], vmin=0, vmax=6)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(div[:,:,59],vmin=-0.3,vmax=0.3)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.3,0.3,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ) )"
      ],
      "metadata": {
        "id": "Kf4-Q_CK5gcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sic_solid_temp = sic_solid[1:2,:,:,:,:]\n",
        "\n",
        "xversion = 'X1-3'\n",
        "x_model_name = 'UnetRS_Modelv{}'.format(xversion)\n",
        "x_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(x_model_name, x_model_name ) )\n",
        "\n",
        "yversion = 'Y1-1'\n",
        "y_model_name = 'UnetRS_Modelv{}'.format(yversion)\n",
        "y_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(y_model_name, y_model_name ) )\n",
        "\n",
        "zversion = 'Z1-4'\n",
        "z_model_name = 'UnetRS_Modelv{}'.format(zversion)\n",
        "z_model = tf.keras.models.load_model( 'RandomSphere Model/{}/{}.ckpt'.format(z_model_name, z_model_name ) )\n",
        "\n",
        "vx_test_pred = np.float32( x_model.predict( x=[sic_solid_temp] ) )/2\n",
        "vy_test_pred = np.float32( y_model.predict( x=[sic_solid_temp] ) )/2\n",
        "vz_test_pred = np.float32( z_model.predict( x=[sic_solid_temp] ) )\n",
        "\n",
        "print(vz_test_pred.shape)"
      ],
      "metadata": {
        "id": "827ip7ln0xmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_vel = np.append(vx_test_pred, np.append(vy_test_pred, vz_test_pred,axis=-1),axis=-1 )\n",
        "print(temp_vel.shape)\n",
        "\n",
        "temp_vel = temp_vel[0,:,:,:,:]\n",
        "dVxdx = (temp_vel[2:,1:-1,1:-1,0] - temp_vel[:-2,1:-1,1:-1,0])/2\n",
        "dVydy = (temp_vel[1:-1,2:,1:-1,1] - temp_vel[1:-1,:-2,1:-1,1])/2\n",
        "dVzdz = (temp_vel[1:-1,1:-1,2:,2] - temp_vel[1:-1,1:-1,:-2,2])/2\n",
        "div = dVxdx + dVydy + dVzdz\n",
        "\n",
        "\n",
        "plt.imshow(sic_solid_temp[0,:,:,59,0])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(temp_vel[:,:,59,2],vmin=0,vmax=6)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(div[:,:,59],vmin=-0.3,vmax=0.3)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "div_flat = div.flatten()\n",
        "plt.hist(div_flat, np.linspace(-0.3,0.3,100))\n",
        "plt.show()\n",
        "\n",
        "print(np.mean( np.abs(div_flat) ) )"
      ],
      "metadata": {
        "id": "L0qTQejL2qF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_div_loss = div_loss1(sic_vel_minmax[1:2,:,:,:,:], np.expand_dims(temp_vel,axis=0))\n",
        "\n",
        "print(temp_div_loss)"
      ],
      "metadata": {
        "id": "KKSpx1q-HUqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "doLp4_6qWh7d",
        "SJzZnnCXzU4B",
        "G_1GP63bpZI7",
        "fM6Pjiuj-zuv",
        "8SIsIuN2sWBS",
        "H1FdBItwuhbM",
        "IGzya783nltX",
        "cQovoz5NZAXW",
        "rXNH4Be39Hua",
        "S1GLAmqe9H5q",
        "QVvmsf2yJYmR",
        "9eT5HRwnOo1N",
        "32c-jJkHxlfp",
        "kMIXsiodIksX",
        "HuY532xA0ry8"
      ],
      "machine_shape": "hm",
      "name": "Unet Random Sphere.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOT2lCfGrxQ2lY/UyspT7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}